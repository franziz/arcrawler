from lib.news_engine.engine import Engine
from pymongo                import MongoClient
from lib                    import tools
$IMPORT
import bson.json_util
import arrow
import pymongo
import json

class Crawler(object):

	def __init__(self):
		self.crawler_name                   = $CRAWLER_NAME
		self.country                        = $COUNTRY

		self.engine                         = Engine()
		self.engine.network_tools           = $NETWORK_TOOLS
		self.engine.domain                  = $LINK_TO_CRAWL
		self.engine.title_fallback          = json.loads($TITLE_FALLBACK)
		self.engine.content_fallback        = json.loads($CONTENT_FALLBACK)
		self.engine.published_date_fallback = json.loads($PUBLISHED_DATE_FALLBACK)
		self.engine.author_name_fallback    = json.loads($AUTHOR_NAME_FALLBACK)
	#end def

	def crawl(self):
		assert self.engine           is not None, "engine is not defined."
		assert len(self.engine.urls) > 0        , "No urls found."
		
		url = self.engine.urls[0]
		try:
			str_processing = "[test][{CRAWLER_NAME}] Processing: {URL}".format(
								CRAWLER_NAME = self.crawler_name,
								         URL = url
							)
			print(str_processing.encode("utf-8"))
			self.engine.parse(url=url)

			assert self.engine.content     is not None, "result has to have content."
			assert self.engine.title       is not None, "result has to have title."
			assert self.engine.author_name is not None, "result has to have author_name"

			published_date = self.engine.published_date if self.engine.published_date is not None else arrow.utcnow().datetime
			document       = {
								           "url": self.engine.url,
								       "content": self.engine.content,
								         "title": self.engine.title,
								"published_date": self.engine.published_date,
								   "author_name": self.engine.author_name,
								  "_insert_time": arrow.utcnow().datetime,
								      "_country": self.country,
								   "_crawled_by": self.crawler_name
							}
			print(bson.json_util.dumps(document,indent=4, separators=(",",":")))
		except pymongo.errors.DuplicateKeyError as duplicate:
			print("[test][{}] Ops! Duplicate Data!".format(self.crawler_name))
		except AssertionError:
			print("[test][{}] Assertion is not passed! Data will not be inserted".format(self.crawler_name))
		#end try
	#end def
#end class