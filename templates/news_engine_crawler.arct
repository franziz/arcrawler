from lib.news_engine.engine import Engine
from pymongo                import MongoClient
from lib                    import tools
$IMPORT
import arrow
import pymongo
import json

class Crawler(object):

	def __init__(self):
		self.crawler_name      = $CRAWLER_NAME
		self.country           = $COUNTRY

		self.db = MongoClient("mongodb://{DB_SERVER_ADDRESS}/{DB_SERVER_NAME}".format(
					DB_SERVER_ADDRESS = $DB_SERVER_ADDRESS,
					   DB_SERVER_NAME = $DB_SERVER_NAME
				))
		self.db = self.db[$DB_SERVER_NAME]

		tools._force_create_index(db=self.db, collection="data", field="permalink")

		self.engine                      = Engine()
		self.engine.network_tools        = $NETWORK_TOOLS
		self.engine.url                  = $LINK_TO_CRAWL
		self.engine.title_xpath          = $TITLE_XPATH
		self.engine.author_name_xpath    = $AUTHOR_NAME_XPATH
		self.engine.content_xpath        = $CONTENT_XPATH
		self.engine.published_date_xpath = $PUBLISHED_DATE_XPATH
	#end def

	def crawl(self):
		assert self.engine is not None, "engine is not defined."
		assert self.db is not None, "db is not defined."

		self.engine.parse()
		self.engine.extract()
		for article in self.engine.articles:
			try:
				str_processing = "[{CRAWLER_NAME}] Processing: {URL}".format(
					CRAWLER_NAME = self.crawler_name,
					         URL = article.url.encode("utf-8")
				)
				print(str_processing)

				assert article.content     is not None, "result has to have content."
				assert article.content                , "content cannot be empty"
				assert article.title       is not None, "result has to have title."
				assert article.title                  , "title cannot be empty"
				assert article.author_name is not None, "result has to have author_name"
				assert article.author_name            , "author_name cannot be empty"

				self.db.data.insert_one({
					     "permalink": article.url,
					       "content": article.content,
					         "title": article.title,
					"published_date": article.published_date,
					   "author_name": article.author_name,
					  "_insert_time": arrow.utcnow().datetime,
					      "_country": self.country,
					   "_crawled_by": self.crawler_name,
					  "_source_type": "news"
				})
				print("[{}] Inserted one document.".format(self.crawler_name))				
			except pymongo.errors.DuplicateKeyError as duplicate:
				print("[{}] Ops! Duplicate Data!".format(self.crawler_name))
			except AssertionError:
				print("[{}] Assertion is not passed! Data will not be inserted".format(self.crawler_name))
			#end try
		#end for
	#end def
#end class